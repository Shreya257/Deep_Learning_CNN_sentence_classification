# Deep_Learning_CNN_sentence_classification

![CNN-architecture-for-short-document-classification-taken-from-Zhang-and-Wallace-2015](https://user-images.githubusercontent.com/76741091/149726304-5fd25b68-1efd-47e9-81e2-1edb5260ed31.png)

# Deep_Learning_CNN_sentence_classification

In our experiment it can be seen that fastText outperforms the other models by quite some way. 
For the code use (cnn_sentence_classification.ipynb) . Our results are pretty close to Kimâ€™s paper result.
The implementation by the authors was in PyTorch, and introduced a learning curve, having only worked in TensorFlow. 
The model can take advantages of unsupervised pre-training of word vectors to improve overall performance.

We report on a series of experiments with convolutional neural networks (CNN) trained on top of pre-trained word vectors for sentence-level classification tasks. We show that a simple CNN with little hyperparameter tuning and static vectors achieves excellent results on multiple benchmarks. Learning task-specific vectors through fine-tuning offers further gains in performance. We additionally propose a simple modification to the architecture to allow for the use of both task- specific and static vectors. We are building and training CNN model with PyTorch. Our results show that unsupervised pre-training of word vectors is an important ingredient in deep learning for NLP.

# Application screenshots-

![image](https://user-images.githubusercontent.com/76741091/159180170-25350702-10dd-4a5a-81c8-6c0d6e601780.png)
![image](https://user-images.githubusercontent.com/76741091/159180376-3059550b-4812-48e1-a791-e46392acd6b5.png)
![image](https://user-images.githubusercontent.com/76741091/159180444-b6b0f400-a223-4be2-8b51-1bcfb3bf6323.png)
![image](https://user-images.githubusercontent.com/76741091/159181062-6a38ccb7-d287-4e8c-a37e-f60821f95808.png)
